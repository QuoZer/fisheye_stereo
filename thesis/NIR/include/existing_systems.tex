
\subsection{Обзор существующих систем стереозрения}


Как правило, система стереозрения состоит из двух камер, наблюдающих сцену с разных точек, как изображено на рисунке \ref{pic:epipol} \cite{Hartley2004}. 
Фундаментальная основа принципа заключается в предположении, что каждой точке в пространстве соответствует уникальная пара пикселей на снимках с двух камер.  

При этом к камерам предъявляются некоторые требования \cite{rusoverview}:   % не уверен, что это надо цитировать
\begin{itemize}
	\item Камеры откалиброваны. Это значит, что известны внутренние (оптические) и внешние (расположение камер в пространстве) параметры камер. 
	\item Ректификация. Подразумевает выравнивание изображения с обеих камер по строкам.  % Мб подробнее расписать  
	\item Ламбертовость поверхностей. Означает независимость освещения наблюдаемых поверхностей от угла зрения. 
\end{itemize}

Таким образом, соблюдение указанных выше требований позволяет использовать следующий геометрический принцип. При наличии двух камеры, как изображено 
на рисунке \ref{pic:epipol}, где $C$ — центр первой камеры, $C'$ — центр второй камеры, точка пространства $X$  
проецируется в $x$ на плоскость изображения левой камеры и в $x'$ на плоскость изображения правой камеры. Прообразом точки $x$ на изображении левой 
камеры является луч $xX$. Этот луч проецируется на плоскость второй камеры в прямую $l'$, называемую эпиполярной линией. Образ точки $X$ на плоскости 
изображения второй камеры обязательно лежит на эпиполярной линии $l'$.

\addimghere{epipolar geometry}{0.5}{Эпиполярная геометрия}{pic:epipol}

В результате каждой точке $x$ на изображении левой камеры соответствует эпиполярная линия $l'$ на изображении правой камеры. При этом соответствие для $x$ на 
изображении правой камеры может лежать только на соответствующей эпиполярной линии. Аналогично, каждой точке $x'$ на правом изображении соответствует 
эпиполярная линия $l$ на левом.

Далее с помощью точек $x$ и $x'$ возможно посчитать смещения каждого пикселя одного изображения относительно другого, что даёт карту смещений (disparity map). 
Очевидно, что смещения будут подсчитаны только для точек, видимых обеими камерами. Карта смещений же приводится далее либо к облаку точек, либо к карте глубины. 

Одну из камер можно заменить источником  света, освещающим одну или несколько точек поверхности световым лучом или специальным шаблоном освещения \cite{shapiro}.  % TODO: цитирование страницы  529


...



Распространённые библиотеки машинного зрения (OpenCV, MATLAB CV Toolbox) предлагаю готовые к использованию классы и функции, позволяющие после калибровки
камер получать с помощью них карты глубины. Однако на практике эти методы весьма ограничены. Для стереосопоставления 
используются традиционные методы, приспособленные для классических камер с перспективной проекцией, что не позволяет 
использовать кадры с широкоугольных камер целиком. В результате у этих кадров после устранения искажений остаётся 
угол зрения не более $120^\circ$. Кроме того, библиотечные функции не позволяют задать область интереса для каждой камеры, 
что ограничивает их область применения только для копланарного расположения сенсоров.  

Исследователи предложили несколько реализаций систем стереозрения, опирающихся на снимки со сверхширокоугольных 
объективов и лишённых недостатков распространённых решений.  
% Вообще, в этой работе и вся та же тема с поворотами есть 
Например, метод, предложенный в \cite{omni_stereo}, позволяет создать кольцевую область стереозрения с вертикальным  %Метод с разворотом камер на 180  ...
полем зрения $65^\circ$. Для этого используются две $245^\circ$ камеры, закреплённые на противоположных концах жёсткого стержня.  
Это позволяет достигнуть панорамного обзора глубины с качеством, достаточным для осуществления автономной навигации и
локализации \cite{omni_copter}, но доступна такая схема расположения камер только летательным аппаратам.  

Другие авторы \cite{direct_neuro_stereo} решили отказаться от типичных для стереозрения этапов устранения искажений и ректификации % FIXME: пояснить ректификацию? 
и извлекать информацию о глубине напрямую по двум снимкам fisheye-камер. Для производства карт глубины используется 
свёрточная неиронная сеть, что требует существенных вычислительных мощностей - для достижения производительности в реальном 
времени разработчикам понадобилось использовать компьютер с ЦПУ i7-4770 и ГПУ NVIDIA GTX 1080Ti. В мобильном автономном роботе
такой вычислитель разместить может быть проблематично. Кроме того, метод так же предполагает, что обе камеры направлены в одном 
направлении. 

\pdfcomment{ монокулярные fisheye-методы }

% Были предложены ортогональные методы, но до реализации не дошло ...