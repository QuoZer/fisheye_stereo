\subsection{Модель сверхширокоугольной камеры}
\label{camera_model}
Сверхширокоугольные объективы имеют в своей основе сложную систему линз, схема которой вместе с примером изображения представлена на рисунке \ref{pic:fyscheme}. 
Особенности этой системы позволяют достигать существенного угла обзора, но также являются причиной аберрации и характерных искажений 
изображения. Моделировать реальный ход лучей в подобных камерах нецелесообразно, поэтому исследователи прибегают к моделям камер.   % FIXME: meh

\addtwoimghere{fisheye_scheme}{0.5}{fisheye_example}{0.5}{Схема хода лучей объектива "рыбий глаз" (слева), пример изображения (справа) \ref{fy_exmp}}{pic:fyscheme}

Как видно по рисунку \ref{pic:fy_geom}, модель проекции для камеры это функция (обычно обозначаемая $\pi_c(\cdot )$), которая моделирует преобразование 
из точки трёхмерного пространства ($P=[x_c, y_c, z_c]^T$) в области зрения камеры в точку на плоскости изображения ($p=[u, \nu]^T$). Единичная            % не совсем единичная 
полусфера $S$ с центром в точке $O_c$ описывает поле зрения. На ней также лежит точка $P_C$, являющаяся результатом обратной проекции $\pi^{-1}_c({p})$.
Угол $\theta$ является углом падения для рассматриваемой точки, а угол $\phi$ откладывается между положительным направлением оси $u$ и $O_{i}{p}$. 

\addimghere{projection_geometry}{0.5}{Схема проекции точки трёхмерного пространства в точку на изображении}{pic:fy_geom}

Модели камер включают в себя описания нескольких типов искажений, но в сверхширокоугольных объективах самыми существенными являются радиальные - искажения, 
проявляющиеся сильнее ближе к краям изображения. Поэтому далее в этой секции модели будут рассматриваться именно с точки зрения описания радиальных искажений. 

Перспективная проекция, которая обычно используется в качестве модели ортоскопической камеры, не способна спроецировать широкоугольное пространство на кадр 
конечного размера. Поэтому при описании и проектировании fisheye-объективов опираются на другие виды проекций \cite{projections}. Но реальные линзы не всегда в 
точности следуют заданным моделям, к тому же отличия в используемых параметрах усложняют процесс калибровки камер. По этой причине радиальные искажения часто 
аппроксимируют многочленами, например, вида
 \begin{equation}	\pdfcomment{ переписать уравнение }
	\begin{split}
        \delta r= k_1 r^3 + k_2 r^5 + k_3 r^7 + ... + k_n r^{n+2},
        \label{eqn:fisheye_distortion}
    \end{split}
\end{equation}
где $k_i$ - коэффициенты, описывающие внутренние параметры камеры. 

В настоящий момент есть несколько распространённых моделей, аппроксимирующих реальные искажения подобных объективов. Модель Канналы и 
Брандта \cite{opencv_model} реализована в OpenCV и описывает радиальные искажения через угол падения луча света на линзу, а не расстояние  
от центра изображения до места падения, как это делалось в более ранних моделях. Авторы посчитали, что для описания типичных искажений достаточно 
пяти членов полинома. Таким образом, указанную модель можно записать следующими уравнениями:
\begin{equation}	
        \theta = \arctan(\frac{r}{f}),
        \label{eqn:kannala_theta}
\end{equation}

\begin{equation}	
    \delta r = k_1\theta + k_2\theta^3 + k_3\theta^5 + k_4\theta^7 + k_5\theta^9,
    \label{eqn:kannala_r}
\end{equation}

\begin{equation}	
    \begin{pmatrix}u\\v\end{pmatrix} = \delta r(\theta)\begin{pmatrix}cos(\phi)\\sin(\phi)\end{pmatrix},
    %\delta r = k_1\theta + k_2\theta^3 + k_3\theta^5 + k_4\theta^7 + ... + k_n\theta^{n+1}
    \label{eqn:kannala_uv}
\end{equation}
где $\theta$ - угол падения луча, определяемый выбранным типом проекции; $\phi$ - угол между горизонтом 
и проекцией падающего луча на плоскость изображения; $r$ - расстояние от спроектированной точки до центра
изображения; $f$ - фокусное расстояние.

Также большое распространение получила модель Скарамуззы \cite{scaramuzza}, которая легла в основу Matlab Omnidirectional 
Camera Calibration Toolbox. Она связывает точки на изображении с соответствующей им точкой в координатах камеры 
следующим образом
\begin{equation}	
    \begin{pmatrix}X_c\\Y_c\\Z_c\end{pmatrix} = \lambda \begin{pmatrix}u\\v\\a_0 + a_2 r^2 + a_3 r^3 + a_4 r^4\end{pmatrix},
    %\delta r = k_1\theta + k_2\theta^3 + k_3\theta^5 + k_4\theta^7 + ... + k_n\theta^{n+1}
    \label{eqn:scaramuzza}
\end{equation}
где $a_0 ... a_4$ - коэффициенты, описывающие внутренние параметры камеры; $\lambda$ - масштабный коэффициент.



\pdfcomment{ дописать  например double sphere model }



\subsection{Обзор существующих систем стереозрения, использующих сверхширокоугольные камеры}

Распространённые библиотеки машинного зрения (OpenCV, MATLAB CV Toolbox) предлагаю готовые к использованию классы и функции, позволяющие после калибровки
камер получать с помощью них карты глубины. Однако на практике эти методы весьма ограничены. Для стереосопоставления 
используются традиционные методы, приспособленные для классических камер с перспективной проекцией, что не позволяет 
использовать кадры с широкоугольных камер целиком. В результате у этих кадров после устранения искажений остаётся 
угол зрения порядка $90^\circ$. Кроме того, библиотечные функции не позволяют задать область интереса для каждой камеры, 
что ограничивает их область применения только для копланарного расположения камер.   \pdfcomment{ найти источник }

Исследователи предложили несколько реализаций стереозрения, опирающихся на снимки со сверхширокоугольных 
объективов и лишённых недостатков распространённых решений.  
% Вообще, в этой работе и вся та же тема с поворотами есть 
Например, метод, предложенный в \cite{omni_stereo}, позволяет создать кольцевую область стереозрения с вертикальным  %Метод с разворотом камер на 180  ...
полем зрения $65^\circ$. Для этого используются две $245^\circ$ камеры, закреплённые на противоположных концах жёсткого стержня.  
Это позволяет достигнуть панорамного обзора глубины с качеством, достаточным для осуществления автономной навигации и
локализации \cite{omni_copter}, но доступна такая схема расположения камер только летательным аппаратам.  

Другие авторы \cite{direct_neuro_stereo} решили отказаться от типичных для стереозрения этапов устранения искажений и ректификации % FIXME: пояснить ректификацию? 
и извлекать информацию о глубине напрямую по двум снимкам fisheye-камер. Для производства карт глубины используется 
свёрточная неиронная сеть, что требует существенных вычислительных мощностей - для достижения производительности в реальном 
времени разработчикам понадобилось использовать компьютер с ЦПУ i7-4770 и ГПУ NVIDIA GTX 1080Ti. В мобильном автономном роботе
такой вычислитель разместить может быть проблематично. Кроме того, метод так же предполагает, что обе камеры направлены в одном 
направлении. 

\pdfcomment{ монокулярные fisheye-методы }

% Были предложены ортогональные методы, но до реализации не дошло ...
 