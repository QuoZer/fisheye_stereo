\include{settings}

\begin{document}	% начало документа

\include{titlepage}


% Содержание
\tableofcontents
\newpage


\section{Введение}

Получение трёхмерной структуры пространства по стереоснимкам - это задача, первые решения которой
были получены десятилетия назад. Ранние работы фокусировались в основном на способах поиска соответствий
и геометрических основах, лежащих в основе процесса. Существенный объём научной работы продолжает
 производиться в области стереозрения и по сей день. Был достигнут заметный прогресс в повышении точности результатов и понижении вычислительных мощностей, требуемых для 
их достижении, однако эти области остаются фокусом исследований. 

Улучшение точности и производительности алгоритмов является нетривиальной задачей. На точность 
полученных результатов оказывает влияние нехватка информации, вызванная заслонением объектов, наличием наклонных
плоскостей и другими факторами, влияющими на сложность восстановления трёхмерных объектов. Разрешение
сенсоров также растёт с каждым годом, увеличивая вычислительную сложность поиска соответствий на кадрах с 
каждой камеры. Таким образом, исследователи в области стереозрения пытаются найти компромисс между этими
 двумя характеристиками. Однако для каждого конкретного алгоритма этот компромисс может быть смещён в 
 ту или иную сторону. 

Первые работы (1970-1980гг) выполнялись преимущественно в ...


Остальная часть статьи организована следующим образом:
...

\subsection{Принцип стереозрения}

Несмотря на существование разных алгоритмов стереозрения, все они реализуют общий принцип. Задача стереозрения - 
 состоит в использовании двух или более камер для получения данных о дальности до объектов в кадре. Существуют способы \cite{singlecamrev} решения
 этой задачи с использованием лишь одной камеры совместно с системой линз и зеркал, но принцип их функционирования по своей сути 
 симулирует двухкамерную реализацию.  %% TODO: некрасиво, стоит переписать

Как правило, система стереозрения состоит из двух камер, наблюдающих сцену с разных точек, как изображено на рисунке \ref{pic:epipol} \cite{Hartley2004}. Фундаментальная основа принципа    %
заключается в предположении, что каждой точке в пространстве соответствует уникальная пара пикселей на снимках с двух камер.  

При этом к камерам предъявляются некоторые требования \cite{rusoverview}:   % не уверен, что это надо цитировать
\begin{itemize}
	\item Камеры откалиброваны. Это значит, что известны внутренние (оптические) и внешние (расположение камер в пространстве) параметры камер. 
	\item Ректификация. Подразумевает выравнивание изображения с обеих камер по строкам.  % Мб подробнее расписать  
	\item Ламбертовость поверхностей. Означает независимость освещения поверхности от угла зрения. 
\end{itemize}

\begin{figure}[H]
	\begin{center}
		\includegraphics[scale=0.5]{pics/epipolar geometry.png}
		\caption{Эпиполярная геометрия} 
		\label{pic:epipol} % название для ссылок внутри кода
	\end{center}
\end{figure}

Таким образом, соблюдение указанных выше требований позволяет использовать следующий геометрический принцип. Пусть имеются две камеры, как изображено 
на рисунке \ref{pic:epipol}. $C$ — центр первой камеры, $C'$ — центр второй камеры. Точка пространства $X$  
проецируется в $x$ на плоскость изображения левой камеры и в $x'$ на плоскость изображения правой камеры. Прообразом точки $x$ на изображении левой 
камеры является луч $xX$. Этот луч проецируется на плоскость второй камеры в прямую $l'$, называемую эпиполярной линией. Образ точки $X$ на плоскости 
изображения второй камеры обязательно лежит на эпиполярной линии $l'$.
% TODO: таким образом повторяется -> ?
Таким образом, каждой точке $x$ на изображении левой камеры соответствует эпиполярная линия $l'$ на изображении правой камеры. При этом пара для $x$ на 
изображении правой камеры может лежать только на соответствующей эпиполярной линии. Аналогично, каждой точке $x'$ на правом изображении соответствует 
эпиполярная линия $l$ на левом.

Далее с помощью точек $x$ и $x'$ возможно посчитать смещения каждого пикселя одного изображения относительно другого, что даёт карту смещений (disparity map). 
Очевидно, что смещения будут подсчитаны только для точек, видимых обеими камерами. Карта смещений же приводится либо к облаку точек, либо к карте глубины. Пример
такой карты представлен на рисунке \ref{pic:depth} \cite{lipson2021raft}. 

%После нахождения карты смещения остаётся по известным внешним параметрам камер рассчитать глубину. Глубина каждой точки P, воспринимаемой двумя камерами 
%с оптическими центрами Ol и Or, определяется проекциями p, p' этой точки на каждый кадр. Тогда значение глубины по уравнению, указанному ниже []. 
%Z = f{T \over d},\eqno{\hbox{(2.1)}}
%где T - расстояние между Ol и Or;
%    d - смещение,  {d = x - x'};
%	f - фокусное расстояние камеры.

\begin{figure}[H]
	\begin{center}
		\includegraphics[scale=0.7]{pics/exmpl.jpg}
		\caption{Примеры результата работы} 
		\label{pic:depth} % название для ссылок внутри кода
	\end{center}
\end{figure}

На практике работу большинства алгоритмов можно разделить на 3 этапа: получение изображений, поиск соответствий и восстановление информации о глубине. Это позволяет
организовать классификацию алгоритмов на основе подходов к каждому из этих этапов. 
% получает два снимка с синхронизированных камер, решает проблему поиска соответствий для сопоставления пикселей на снимках, соответствующих 
%одной точке пространства и затем восстанавливает информацию о глубине. Результатом является карта глубины изображения или облако точек. 

\section{Восстановление}

\section{Поиск соответствий}

Как было ранее сказано, поиск соответствий можно выполнять широким набором методов. Цель каждого метода - постараться найти для каждого пикселя одной картинки 
соответствующий ему пиксель на второй. Достичь этого можно двумя подходами в зависимости от накладываемых ограничений на зону поиска соответствий.  При подсчёте 
расхождений лишь в небольшой окрестности или окне вокруг интересующего нас пикселя мы говорим о локальных методах, эти методы  используют небольшое количество 
информации и относительно быстродейственны.Локальные методы в свою очередь делятся на три категории: block matching (сопоставление блоков?), градиентные методы и 
сопоставление особенностей (feature matching). 		//TODO: встаавить правильный перевод

Глобальные методы же проводят поиск в целом ряде пикселей или во всём изображении. Они не так чувствительны к локальным дефектам, мешающим процессу поиска соответствий 
(например, заслонение), но при этом имеют куда большую вычислительную сложность. Одним из самых популярных подходов в этой группе методов является динамическое программирование, 
которое позволяет разбить вычислительно сложную задачу на множество простых подзадач \cite{dynamic_prog}.   	 

\subsection{Block matching}

BM - это локальный метод, который заключается в оценке расхождения в точке на одной картинке с помощью сравнения небольшой области вокруг этой точки с такими же областями 
на другой \cite{}. Благодаря выпрямлению (ректификации) поиск соответствующей области на другой картинке ограничивается одним измерением. Существует целый набор метрик доступных 
к использованию в этом методе. 
Для отдельных пар пикселей можно рассчитывать абсолютную разность (AD) или квадратичную разность (SD), выраженную через их интенсивности:
\begin{equation}
	AD(x, y, d) = |I_l(x,y) - I_r(x+d, y)|,			
	\label{eq:AD}
\end{equation}
где $(x, y)$ - координаты первого пикселя; $d$ - сдвиг по оси x между двумя пикселями или диспаритет; $I$ - интенсивность данного пикселя. Обычно $I_l$ обозначают опорное изображение, а $I_r$ - 
целевое. Абсолютная разность - простейшая метрика, за счёт чего до сих пор используется в многих алгоритмах, от которых требуется производительность в реальном времени []. 

Для квадратичной разности: 
\begin{equation}
	SD(x, y, d) = |I_l(x,y) - I_r(x+d, y)|^2,		
	\label{eq:SD}
\end{equation}



\subsection{Методы динамического программирования}



\section{Получение изображений}


\section{Выводы}

\newpage
\bibliographystyle{plain}
\bibliography{refs}

\end{document}
